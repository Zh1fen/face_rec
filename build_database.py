"""
æ„å»ºäººè„¸ç‰¹å¾æ•°æ®åº“
ä» face_database ç›®å½•ä¸­çš„å›¾ç‰‡æå–ç‰¹å¾å‘é‡å¹¶ä¿å­˜
"""

import os
import time
import logging
from tqdm import tqdm
from typing import Dict, List

from src.face_detector import FaceDetector
from src.feature_extractor import FeatureExtractor
from src.utils import get_image_files, save_features, load_image, setup_directories
from config import FACE_DATABASE_DIR, FEATURES_DIR, DATABASE_CONFIG

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def extract_features_from_person_folder(person_name: str, person_folder: str, 
                                      detector: FaceDetector, 
                                      extractor: FeatureExtractor) -> List[tuple]:
    """
    ä»å•ä¸ªäººå‘˜æ–‡ä»¶å¤¹ä¸­æå–ç‰¹å¾
    
    Args:
        person_name: äººå‘˜å§“å
        person_folder: äººå‘˜æ–‡ä»¶å¤¹è·¯å¾„
        detector: äººè„¸æ£€æµ‹å™¨
        extractor: ç‰¹å¾æå–å™¨
        
    Returns:
        List[tuple]: (ç‰¹å¾å‘é‡, å›¾ç‰‡è·¯å¾„) åˆ—è¡¨
    """
    image_files = get_image_files(person_folder)
    if not image_files:
        logger.warning(f"åœ¨ {person_folder} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return []
    
    features_list = []
    
    logger.info(f"å¤„ç† {person_name} çš„ {len(image_files)} å¼ å›¾ç‰‡")
    
    for image_path in tqdm(image_files, desc=f"æå– {person_name} çš„ç‰¹å¾"):
        try:
            # åŠ è½½å›¾ç‰‡
            image = load_image(image_path)
            if image is None:
                logger.warning(f"æ— æ³•åŠ è½½å›¾ç‰‡: {image_path}")
                continue
            
            # æ£€æµ‹äººè„¸
            detected_faces = detector.detect_and_extract_faces(image)
            
            if not detected_faces:
                logger.warning(f"åœ¨ {image_path} ä¸­æœªæ£€æµ‹åˆ°äººè„¸")
                continue
            
            # å¤„ç†æ£€æµ‹åˆ°çš„æ‰€æœ‰äººè„¸
            for i, face_info in enumerate(detected_faces):
                if not detector.is_valid_face(face_info):
                    continue
                
                # æå–ç‰¹å¾
                features = extractor.extract_features(face_info['tensor'])
                if features is not None:
                    features_list.append((features, image_path, i))
                    logger.debug(f"æˆåŠŸæå–ç‰¹å¾: {image_path} (äººè„¸ {i})")
                else:
                    logger.warning(f"ç‰¹å¾æå–å¤±è´¥: {image_path} (äººè„¸ {i})")
        
        except Exception as e:
            logger.error(f"å¤„ç†å›¾ç‰‡ {image_path} æ—¶å‡ºé”™: {str(e)}")
            continue
    
    logger.info(f"ä» {person_name} çš„å›¾ç‰‡ä¸­æˆåŠŸæå–äº† {len(features_list)} ä¸ªç‰¹å¾å‘é‡")
    return features_list

def calculate_average_features(features_list: List[tuple]) -> tuple:
    """
    è®¡ç®—å¹³å‡ç‰¹å¾å‘é‡
    
    Args:
        features_list: ç‰¹å¾å‘é‡åˆ—è¡¨
        
    Returns:
        tuple: (å¹³å‡ç‰¹å¾å‘é‡, ç‰¹å¾æ•°é‡, æ¥æºä¿¡æ¯)
    """
    if not features_list:
        return None, 0, []
    
    # æå–æ‰€æœ‰ç‰¹å¾å‘é‡
    features_array = [item[0] for item in features_list]
    
    # è®¡ç®—å¹³å‡å€¼
    import numpy as np
    average_features = np.mean(features_array, axis=0)
    
    # å½’ä¸€åŒ–
    average_features = average_features / np.linalg.norm(average_features)
    
    # æ”¶é›†æ¥æºä¿¡æ¯
    sources = [(item[1], item[2]) for item in features_list]
    
    return average_features, len(features_list), sources

def build_face_database(use_average: bool = True, 
                       min_faces_per_person: int = 1) -> bool:
    """
    æ„å»ºäººè„¸ç‰¹å¾æ•°æ®åº“
    
    Args:
        use_average: æ˜¯å¦ä½¿ç”¨å¹³å‡ç‰¹å¾ï¼ˆå¦‚æœFalseï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„ç‰¹å¾ï¼‰
        min_faces_per_person: æ¯ä¸ªäººæœ€å°‘éœ€è¦çš„äººè„¸æ•°é‡
        
    Returns:
        bool: æ˜¯å¦æ„å»ºæˆåŠŸ
    """
    logger.info("å¼€å§‹æ„å»ºäººè„¸ç‰¹å¾æ•°æ®åº“")
    
    # æ£€æŸ¥ç›®å½•
    if not os.path.exists(FACE_DATABASE_DIR):
        logger.error(f"äººè„¸æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨: {FACE_DATABASE_DIR}")
        logger.info("è¯·åœ¨ face_database/ ç›®å½•ä¸­æŒ‰äººååˆ›å»ºå­æ–‡ä»¶å¤¹å¹¶æ”¾å…¥ç›¸åº”çš„ç…§ç‰‡")
        return False
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    setup_directories([FEATURES_DIR])
    
    # è·å–æ‰€æœ‰äººå‘˜æ–‡ä»¶å¤¹
    person_folders = []
    for item in os.listdir(FACE_DATABASE_DIR):
        person_path = os.path.join(FACE_DATABASE_DIR, item)
        if os.path.isdir(person_path):
            person_folders.append((item, person_path))
    
    if not person_folders:
        logger.error(f"åœ¨ {FACE_DATABASE_DIR} ä¸­æ²¡æœ‰æ‰¾åˆ°äººå‘˜æ–‡ä»¶å¤¹")
        logger.info("è¯·æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡æ–‡ä»¶:")
        logger.info("face_database/")
        logger.info("  â”œâ”€â”€ å¼ ä¸‰/")
        logger.info("  â”‚   â”œâ”€â”€ photo1.jpg")
        logger.info("  â”‚   â””â”€â”€ photo2.jpg")
        logger.info("  â””â”€â”€ æå››/")
        logger.info("      â””â”€â”€ photo1.jpg")
        return False
    
    logger.info(f"å‘ç° {len(person_folders)} ä¸ªäººå‘˜æ–‡ä»¶å¤¹: {[name for name, _ in person_folders]}")
    
    # åˆå§‹åŒ–æ£€æµ‹å™¨å’Œæå–å™¨
    try:
        logger.info("åˆå§‹åŒ–äººè„¸æ£€æµ‹å™¨å’Œç‰¹å¾æå–å™¨...")
        detector = FaceDetector()
        extractor = FeatureExtractor()
    except Exception as e:
        logger.error(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        return False
    
    # å­˜å‚¨æ‰€æœ‰ç‰¹å¾
    database_features = {}
    database_info = {}
    
    total_start_time = time.time()
    
    # å¤„ç†æ¯ä¸ªäººå‘˜æ–‡ä»¶å¤¹
    for person_name, person_folder in person_folders:
        logger.info(f"\nå¤„ç†äººå‘˜: {person_name}")
        
        start_time = time.time()
        features_list = extract_features_from_person_folder(
            person_name, person_folder, detector, extractor
        )
        processing_time = time.time() - start_time
        
        if len(features_list) < min_faces_per_person:
            logger.warning(f"è·³è¿‡ {person_name}: æ£€æµ‹åˆ°çš„äººè„¸æ•°é‡({len(features_list)}) "
                          f"å°‘äºæœ€å°è¦æ±‚({min_faces_per_person})")
            continue
        
        if use_average:
            # ä½¿ç”¨å¹³å‡ç‰¹å¾
            avg_features, count, sources = calculate_average_features(features_list)
            if avg_features is not None:
                database_features[person_name] = avg_features
                database_info[person_name] = {
                    'method': 'average',
                    'feature_count': count,
                    'sources': sources,
                    'processing_time': processing_time
                }
                logger.info(f"å·²ä¿å­˜ {person_name} çš„å¹³å‡ç‰¹å¾ (åŸºäº {count} ä¸ªç‰¹å¾)")
        else:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰¹å¾
            if features_list:
                database_features[person_name] = features_list[0][0]
                database_info[person_name] = {
                    'method': 'first',
                    'feature_count': 1,
                    'sources': [(features_list[0][1], features_list[0][2])],
                    'processing_time': processing_time
                }
                logger.info(f"å·²ä¿å­˜ {person_name} çš„ç‰¹å¾ (æ¥æº: {features_list[0][1]})")
    
    total_processing_time = time.time() - total_start_time
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆç‰¹å¾
    if not database_features:
        logger.error("æ²¡æœ‰æˆåŠŸæå–ä»»ä½•ç‰¹å¾ï¼Œæ•°æ®åº“æ„å»ºå¤±è´¥")
        return False
    
    # ä¿å­˜ç‰¹å¾æ•°æ®åº“
    features_file = DATABASE_CONFIG['features_file']
    
    # å‡†å¤‡ä¿å­˜çš„æ•°æ®
    save_data = {
        'features': database_features,
        'info': database_info,
        'metadata': {
            'total_persons': len(database_features),
            'build_time': time.time(),
            'processing_time': total_processing_time,
            'use_average': use_average,
            'min_faces_per_person': min_faces_per_person
        }
    }
    
    if save_features(save_data, features_file):
        logger.info(f"\nâœ… æ•°æ®åº“æ„å»ºæˆåŠŸ!")
        logger.info(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"  - æ€»äººæ•°: {len(database_features)}")
        logger.info(f"  - ç‰¹å¾æ–‡ä»¶: {features_file}")
        logger.info(f"  - æ€»è€—æ—¶: {total_processing_time:.2f} ç§’")
        logger.info(f"  - å¹³å‡æ¯äºº: {total_processing_time/len(database_features):.2f} ç§’")
        
        # æ˜¾ç¤ºæ¯ä¸ªäººçš„è¯¦ç»†ä¿¡æ¯
        logger.info(f"\nğŸ“‹ äººå‘˜è¯¦æƒ…:")
        for name, info in database_info.items():
            logger.info(f"  - {name}: {info['feature_count']} ä¸ªç‰¹å¾, "
                       f"{info['processing_time']:.2f}s")
        
        return True
    else:
        logger.error("ä¿å­˜ç‰¹å¾æ•°æ®åº“å¤±è´¥")
        return False

def validate_database() -> bool:
    """
    éªŒè¯æ•°æ®åº“å®Œæ•´æ€§
    
    Returns:
        bool: æ•°æ®åº“æ˜¯å¦æœ‰æ•ˆ
    """
    features_file = DATABASE_CONFIG['features_file']
    
    if not os.path.exists(features_file):
        logger.error(f"ç‰¹å¾æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {features_file}")
        return False
    
    try:
        from src.utils import load_features
        data = load_features(features_file)
        
        if data is None:
            logger.error("æ— æ³•åŠ è½½ç‰¹å¾æ•°æ®åº“")
            return False
        
        # æ£€æŸ¥æ•°æ®ç»“æ„
        if 'features' not in data:
            logger.error("æ•°æ®åº“ç¼ºå°‘ 'features' å­—æ®µ")
            return False
        
        features = data['features']
        info = data.get('info', {})
        metadata = data.get('metadata', {})
        
        logger.info(f"âœ… æ•°æ®åº“éªŒè¯æˆåŠŸ")
        logger.info(f"  - äººå‘˜æ•°é‡: {len(features)}")
        logger.info(f"  - æ„å»ºæ—¶é—´: {time.ctime(metadata.get('build_time', 0))}")
        
        # éªŒè¯ç‰¹å¾å‘é‡
        import numpy as np
        for name, feature_vec in features.items():
            if not isinstance(feature_vec, np.ndarray):
                logger.error(f"äººå‘˜ {name} çš„ç‰¹å¾ä¸æ˜¯numpyæ•°ç»„")
                return False
            
            if feature_vec.shape[0] != 512:  # FaceNetç‰¹å¾ç»´åº¦
                logger.warning(f"äººå‘˜ {name} çš„ç‰¹å¾ç»´åº¦å¼‚å¸¸: {feature_vec.shape}")
        
        return True
        
    except Exception as e:
        logger.error(f"éªŒè¯æ•°æ®åº“æ—¶å‡ºé”™: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ„å»ºäººè„¸ç‰¹å¾æ•°æ®åº“')
    parser.add_argument('--no-average', action='store_true', 
                       help='ä¸ä½¿ç”¨å¹³å‡ç‰¹å¾ï¼Œåªä½¿ç”¨ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„ç‰¹å¾')
    parser.add_argument('--min-faces', type=int, default=1,
                       help='æ¯ä¸ªäººæœ€å°‘éœ€è¦çš„äººè„¸æ•°é‡ (é»˜è®¤: 1)')
    parser.add_argument('--validate', action='store_true',
                       help='éªŒè¯ç°æœ‰æ•°æ®åº“')
    
    args = parser.parse_args()
    
    if args.validate:
        # éªŒè¯æ•°æ®åº“
        if validate_database():
            logger.info("æ•°æ®åº“éªŒè¯é€šè¿‡")
        else:
            logger.error("æ•°æ®åº“éªŒè¯å¤±è´¥")
            exit(1)
    else:
        # æ„å»ºæ•°æ®åº“
        use_average = not args.no_average
        success = build_face_database(
            use_average=use_average,
            min_faces_per_person=args.min_faces
        )
        
        if success:
            logger.info("æ•°æ®åº“æ„å»ºå®Œæˆï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨äººè„¸è¯†åˆ«ç³»ç»Ÿ")
        else:
            logger.error("æ•°æ®åº“æ„å»ºå¤±è´¥")
            exit(1)

if __name__ == '__main__':
    main()
